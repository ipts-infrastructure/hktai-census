events {
    worker_connections 1024;
}

http {

    # Log format including upstream server info
    log_format upstreamlog '$remote_addr - $remote_user [$time_local] '
                        '"$request" $status $body_bytes_sent '
                        '"$http_referer" "$http_user_agent" '
                        'upstream=$upstream_addr';

    access_log /var/log/nginx/access.log upstreamlog;

    upstream lm_studio_grp_1 {
        server 192.168.0.200:1234;
    }

    upstream lm_studio_grp_2 {
        # Using nginx as HTTP load balancer
        # https://nginx.org/en/docs/http/load_balancing.html
        # Default Round Robin: Distributed evenly across the servers
        # ip_hash; # Based on the hash value of client IP
        # least_conn; # Next request is assigned to the server with the least number of active connections,
        # Weight example: server 192.168.0.200:1234 weight=5; (send around 50% of the request)

        server 192.168.0.200:1234; # Real lm studio server
        server 172.26.156.55:8000; # Flask proxy server
    }

    upstream flask_grp {
        server flask1:5000;
        server flask2:5000;
    }

    server {
        
        listen 80;

        # Request to LM studio with load balancing
        location /v1/chat/completions {
            proxy_pass http://lm_studio_grp_2/v1/chat/completions;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        # Test GET Request
        location /flask {
            proxy_pass http://flask_grp/health;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
